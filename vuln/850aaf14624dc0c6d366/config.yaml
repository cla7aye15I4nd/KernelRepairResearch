id: 850aaf14624dc0c6d366
bug_link: https://syzkaller.appspot.com/bug?extid=850aaf14624dc0c6d366
title: possible deadlock in __bpf_ringbuf_reserve
source_page: https://syzkaller.appspot.com/upstream/fixed
trigger_commit: 2f41503d647629cfafea42cf6f827e4139536703
fix_commit: a650d38915c194b87616a0747a339b20958d17db
datetime: '2025-04-11T10:28:26-07:00'
fix_commit_message: 'bpf: Convert ringbuf map to rqspinlock


  Convert the raw spinlock used by BPF ringbuf to rqspinlock. Currently,

  we have an open syzbot report of a potential deadlock. In addition, the

  ringbuf can fail to reserve spuriously under contention from NMI

  context.


  It is potentially attractive to enable unconstrained usage (incl. NMIs)

  while ensuring no deadlocks manifest at runtime, perform the conversion

  to rqspinlock to achieve this.


  This change was benchmarked for BPF ringbuf''s multi-producer contention

  case on an Intel Sapphire Rapids server, with hyperthreading disabled

  and performance governor turned on. 5 warm up runs were done for each

  case before obtaining the results.


  Before (raw_spinlock_t):


  Ringbuf, multi-producer contention

  ==================================

  rb-libbpf nr_prod 1  11.440 ± 0.019M/s (drops 0.000 ± 0.000M/s)

  rb-libbpf nr_prod 2  2.706 ± 0.010M/s (drops 0.000 ± 0.000M/s)

  rb-libbpf nr_prod 3  3.130 ± 0.004M/s (drops 0.000 ± 0.000M/s)

  rb-libbpf nr_prod 4  2.472 ± 0.003M/s (drops 0.000 ± 0.000M/s)

  rb-libbpf nr_prod 8  2.352 ± 0.001M/s (drops 0.000 ± 0.000M/s)

  rb-libbpf nr_prod 12 2.813 ± 0.001M/s (drops 0.000 ± 0.000M/s)

  rb-libbpf nr_prod 16 1.988 ± 0.001M/s (drops 0.000 ± 0.000M/s)

  rb-libbpf nr_prod 20 2.245 ± 0.001M/s (drops 0.000 ± 0.000M/s)

  rb-libbpf nr_prod 24 2.148 ± 0.001M/s (drops 0.000 ± 0.000M/s)

  rb-libbpf nr_prod 28 2.190 ± 0.001M/s (drops 0.000 ± 0.000M/s)

  rb-libbpf nr_prod 32 2.490 ± 0.001M/s (drops 0.000 ± 0.000M/s)

  rb-libbpf nr_prod 36 2.180 ± 0.001M/s (drops 0.000 ± 0.000M/s)

  rb-libbpf nr_prod 40 2.201 ± 0.001M/s (drops 0.000 ± 0.000M/s)

  rb-libbpf nr_prod 44 2.226 ± 0.001M/s (drops 0.000 ± 0.000M/s)

  rb-libbpf nr_prod 48 2.164 ± 0.001M/s (drops 0.000 ± 0.000M/s)

  rb-libbpf nr_prod 52 1.874 ± 0.001M/s (drops 0.000 ± 0.000M/s)


  After (rqspinlock_t):


  Ringbuf, multi-producer contention

  ==================================

  rb-libbpf nr_prod 1  11.078 ± 0.019M/s (drops 0.000 ± 0.000M/s) (-3.16%)

  rb-libbpf nr_prod 2  2.801 ± 0.014M/s (drops 0.000 ± 0.000M/s) (3.51%)

  rb-libbpf nr_prod 3  3.454 ± 0.005M/s (drops 0.000 ± 0.000M/s) (10.35%)

  rb-libbpf nr_prod 4  2.567 ± 0.002M/s (drops 0.000 ± 0.000M/s) (3.84%)

  rb-libbpf nr_prod 8  2.468 ± 0.001M/s (drops 0.000 ± 0.000M/s) (4.93%)

  rb-libbpf nr_prod 12 2.510 ± 0.001M/s (drops 0.000 ± 0.000M/s) (-10.77%)

  rb-libbpf nr_prod 16 2.075 ± 0.001M/s (drops 0.000 ± 0.000M/s) (4.38%)

  rb-libbpf nr_prod 20 2.640 ± 0.001M/s (drops 0.000 ± 0.000M/s) (17.59%)

  rb-libbpf nr_prod 24 2.092 ± 0.001M/s (drops 0.000 ± 0.000M/s) (-2.61%)

  rb-libbpf nr_prod 28 2.426 ± 0.005M/s (drops 0.000 ± 0.000M/s) (10.78%)

  rb-libbpf nr_prod 32 2.331 ± 0.004M/s (drops 0.000 ± 0.000M/s) (-6.39%)

  rb-libbpf nr_prod 36 2.306 ± 0.003M/s (drops 0.000 ± 0.000M/s) (5.78%)

  rb-libbpf nr_prod 40 2.178 ± 0.002M/s (drops 0.000 ± 0.000M/s) (-1.04%)

  rb-libbpf nr_prod 44 2.293 ± 0.001M/s (drops 0.000 ± 0.000M/s) (3.01%)

  rb-libbpf nr_prod 48 2.022 ± 0.001M/s (drops 0.000 ± 0.000M/s) (-6.56%)

  rb-libbpf nr_prod 52 1.809 ± 0.001M/s (drops 0.000 ± 0.000M/s) (-3.47%)


  There''s a fair amount of noise in the benchmark, with numbers on reruns

  going up and down by 10%, so all changes are in the range of this

  disturbance, and we see no major regressions.


  Reported-by: syzbot+850aaf14624dc0c6d366@syzkaller.appspotmail.com

  Closes: https://lore.kernel.org/all/0000000000004aa700061379547e@google.com

  Signed-off-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>

  Link: https://lore.kernel.org/r/20250411101759.4061366-1-memxor@gmail.com

  Signed-off-by: Alexei Starovoitov <ast@kernel.org>

  '
submodule:
- kernel/bpf
hunk_count: 6
covered_count: 5
