id: 55cc72f8cc3a549119df
bug_link: https://syzkaller.appspot.com/bug?extid=55cc72f8cc3a549119df
title: 'BUG: Bad page map (7)'
source_page: https://syzkaller.appspot.com/upstream/fixed
trigger_commit: a501a0703044f00180d7697b32cacd7ff46d02d8
fix_commit: ce60f27bb62dfeb1bf827350520f34abc84e0933
datetime: '2023-09-29T17:20:46-07:00'
fix_commit_message: 'mm: abstract moving to the next PFN


  In order to fix the L1TF vulnerability, x86 can invert the PTE bits for

  PROT_NONE VMAs, which means we cannot move from one PTE to the next by

  adding 1 to the PFN field of the PTE.  This results in the BUG reported at

  [1].


  Abstract advancing the PTE to the next PFN through a pte_next_pfn()

  function/macro.


  Link: https://lkml.kernel.org/r/20230920040958.866520-1-willy@infradead.org

  Fixes: bcc6cc832573 ("mm: add default definition of set_ptes()")

  Signed-off-by: Matthew Wilcox (Oracle) <willy@infradead.org>

  Reported-by: syzbot+55cc72f8cc3a549119df@syzkaller.appspotmail.com

  Closes: https://lkml.kernel.org/r/000000000000d099fa0604f03351@google.com [1]

  Reviewed-by: Yin Fengwei <fengwei.yin@intel.com>

  Cc: Dave Hansen <dave.hansen@intel.com>

  Cc: David Hildenbrand <david@redhat.com>

  Cc: Thomas Gleixner <tglx@linutronix.de>

  Signed-off-by: Andrew Morton <akpm@linux-foundation.org>

  '
submodule:
- arch/x86/include/asm
- include/linux
hunk_count: 3
covered_count: 0
