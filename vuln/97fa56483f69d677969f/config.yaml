id: 97fa56483f69d677969f
bug_link: https://syzkaller.appspot.com/bug?extid=97fa56483f69d677969f
title: possible deadlock in io_uring_register
source_page: https://syzkaller.appspot.com/upstream/fixed
trigger_commit: c57a91fb1ccfa203ba3e31e5a389cb04de5b0561
fix_commit: 009ad9f0c6eed0caa7943bc46aa1ae2cb8c382fb
datetime: '2021-09-08T19:07:26-06:00'
fix_commit_message: "io_uring: drop ctx->uring_lock before acquiring sqd->lock\n\n\
  The SQPOLL thread dictates the lock order, and we hold the ctx->uring_lock\nfor\
  \ all the registration opcodes. We also hold a ref to the ctx, and we\ndo drop the\
  \ lock for other reasons to quiesce, so it's fine to drop the\nctx lock temporarily\
  \ to grab the sqd->lock. This fixes the following\nlockdep splat:\n\n======================================================\n\
  WARNING: possible circular locking dependency detected\n5.14.0-syzkaller #0 Not\
  \ tainted\n------------------------------------------------------\nsyz-executor.5/25433\
  \ is trying to acquire lock:\nffff888023426870 (&sqd->lock){+.+.}-{3:3}, at: io_register_iowq_max_workers\
  \ fs/io_uring.c:10551 [inline]\nffff888023426870 (&sqd->lock){+.+.}-{3:3}, at: __io_uring_register\
  \ fs/io_uring.c:10757 [inline]\nffff888023426870 (&sqd->lock){+.+.}-{3:3}, at: __do_sys_io_uring_register+0x10aa/0x2e70\
  \ fs/io_uring.c:10792\n\nbut task is already holding lock:\nffff8880885b40a8 (&ctx->uring_lock){+.+.}-{3:3},\
  \ at: __do_sys_io_uring_register+0x2e1/0x2e70 fs/io_uring.c:10791\n\nwhich lock\
  \ already depends on the new lock.\n\nthe existing dependency chain (in reverse\
  \ order) is:\n\n-> #1 (&ctx->uring_lock){+.+.}-{3:3}:\n       __mutex_lock_common\
  \ kernel/locking/mutex.c:596 [inline]\n       __mutex_lock+0x131/0x12f0 kernel/locking/mutex.c:729\n\
  \       __io_sq_thread fs/io_uring.c:7291 [inline]\n       io_sq_thread+0x65a/0x1370\
  \ fs/io_uring.c:7368\n       ret_from_fork+0x1f/0x30 arch/x86/entry/entry_64.S:295\n\
  \n-> #0 (&sqd->lock){+.+.}-{3:3}:\n       check_prev_add kernel/locking/lockdep.c:3051\
  \ [inline]\n       check_prevs_add kernel/locking/lockdep.c:3174 [inline]\n    \
  \   validate_chain kernel/locking/lockdep.c:3789 [inline]\n       __lock_acquire+0x2a07/0x54a0\
  \ kernel/locking/lockdep.c:5015\n       lock_acquire kernel/locking/lockdep.c:5625\
  \ [inline]\n       lock_acquire+0x1ab/0x510 kernel/locking/lockdep.c:5590\n    \
  \   __mutex_lock_common kernel/locking/mutex.c:596 [inline]\n       __mutex_lock+0x131/0x12f0\
  \ kernel/locking/mutex.c:729\n       io_register_iowq_max_workers fs/io_uring.c:10551\
  \ [inline]\n       __io_uring_register fs/io_uring.c:10757 [inline]\n       __do_sys_io_uring_register+0x10aa/0x2e70\
  \ fs/io_uring.c:10792\n       do_syscall_x64 arch/x86/entry/common.c:50 [inline]\n\
  \       do_syscall_64+0x35/0xb0 arch/x86/entry/common.c:80\n       entry_SYSCALL_64_after_hwframe+0x44/0xae\n\
  \nother info that might help us debug this:\n\n Possible unsafe locking scenario:\n\
  \n       CPU0                    CPU1\n       ----                    ----\n  lock(&ctx->uring_lock);\n\
  \                               lock(&sqd->lock);\n                            \
  \   lock(&ctx->uring_lock);\n  lock(&sqd->lock);\n\n *** DEADLOCK ***\n\nFixes:\
  \ 2e480058ddc2 (\"io-wq: provide a way to limit max number of workers\")\nReported-by:\
  \ syzbot+97fa56483f69d677969f@syzkaller.appspotmail.com\nSigned-off-by: Jens Axboe\
  \ <axboe@kernel.dk>\n"
submodule:
- fs
hunk_count: 1
covered_count: 1
